# IBPMãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SDAãƒ‡ãƒ¼ã‚¿ã¸ã®å¤‰æ›ã‚¬ã‚¤ãƒ‰

## ç›®æ¬¡
1. [æ¦‚è¦](#æ¦‚è¦)
2. [çµè«–: å¤‰æ›å¯èƒ½æ€§ã®ç¢ºèª](#çµè«–-å¤‰æ›å¯èƒ½æ€§ã®ç¢ºèª)
3. [ãƒ‡ãƒ¼ã‚¿å‹ã®æ¯”è¼ƒ](#ãƒ‡ãƒ¼ã‚¿å‹ã®æ¯”è¼ƒ)
4. [å·®åˆ†ã®è©³ç´°åˆ†æ](#å·®åˆ†ã®è©³ç´°åˆ†æ)
5. [å¤‰æ›å‡¦ç†ã®å®Ÿè£…](#å¤‰æ›å‡¦ç†ã®å®Ÿè£…)
6. [å®Ÿè£…ä¾‹](#å®Ÿè£…ä¾‹)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
8. [ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ](#ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ)
9. [æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)

---

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€**IBPM (Immersed Boundary Projection Method)** ã§ç”Ÿæˆã•ã‚ŒãŸæµä½“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ã€**SDA (Score-based Diffusion for Autoregression)** ã®å­¦ç¿’ãƒ»æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### å¤‰æ›ã®å¿…è¦æ€§
- IBPMã¯æµä½“åŠ›å­¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€Tecplotå½¢å¼(.plt)ã¨ãƒã‚¤ãƒŠãƒªå½¢å¼(.bin)ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
- SDAã¯PyTorchãƒ™ãƒ¼ã‚¹ã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€HDF5å½¢å¼(.h5)ã®NumPyé…åˆ—ã‚’å…¥åŠ›ã¨ã—ã¦æœŸå¾…
- ãƒ‡ãƒ¼ã‚¿å½¢å¼ã€æ¬¡å…ƒã€æ­£è¦åŒ–ãŒç•°ãªã‚‹ãŸã‚ã€æ˜ç¤ºçš„ãªå¤‰æ›å‡¦ç†ãŒå¿…è¦

---

## çµè«–: å¤‰æ›å¯èƒ½æ€§ã®ç¢ºèª

### âœ… IBPMãƒ‡ãƒ¼ã‚¿ã¯SDAå½¢å¼ã«å¤‰æ›å¯èƒ½

IBPMã®å‡ºåŠ›å½¢å¼ã¨SDAã®æœŸå¾…å½¢å¼ã«ã¯**æ§‹é€ ãƒ»è§£åƒåº¦ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«ã®é•ã„**ãŒã‚ã‚Šã¾ã™ãŒã€æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§æç¤ºã™ã‚‹å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆASCIIãƒ‘ãƒ¼ã‚¹ â†’ é€Ÿåº¦æŠ½å‡º â†’ Coarsening â†’ æ™‚ç³»åˆ—åŒ– â†’ HDF5ä¿å­˜ï¼‰ã«ã‚ˆã‚Šã€**SDAãƒ¢ãƒ‡ãƒ«ãŒãã®ã¾ã¾å­¦ç¿’ã§ãã‚‹å½¢å¼ã«æ­£ã—ãå¤‰æ›å¯èƒ½**ã§ã™ã€‚

### ğŸ§© ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®å¯¾å¿œé–¢ä¿‚ï¼ˆã‚µãƒãƒªãƒ¼ï¼‰

| é …ç›® | IBPM | SDA (Kolmogorov Flow) | å¤‰æ›å†…å®¹ |
|------|------|----------------------|----------|
| **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼** | ASCII Tecplot (.plt) / ãƒã‚¤ãƒŠãƒª (.bin) | HDF5 (.h5) | .pltã‚’NumPyã«èª­ã¿è¾¼ã¿ â†’ HDF5ã¸æ›¸ãå‡ºã— |
| **å‡ºåŠ›æ§‹é€ ** | å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«<br>(ibpm00000.plt, ibpm00100.plt, ...) | 1ãƒ•ã‚¡ã‚¤ãƒ«ã«å…¨æ™‚ç³»åˆ—ã‚’æ ¼ç´<br>(train.h5 ãªã©) | .pltç¾¤ã‚’æ™‚ç³»åˆ—æ–¹å‘ã«çµåˆ |
| **å¤‰æ•°** | x, y, u, v, vorticityï¼ˆè¨ˆ5å¤‰æ•°ï¼‰ | u, vï¼ˆ2ãƒãƒ£ãƒãƒ«ï¼‰ | u, vã®ã¿æŠ½å‡º (`extract_velocity`) |
| **ã‚°ãƒªãƒƒãƒ‰æ§‹é€ ** | æ˜ç¤ºçš„åº§æ¨™æ ¼å­ (x, y) | æš—é»™çš„æ ¼å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (i, j) | åº§æ¨™æƒ…å ±ã‚’å‰Šé™¤ã—ã€é…åˆ—ã¨ã—ã¦æ ¼ç´ |
| **è§£åƒåº¦** | ä»»æ„ï¼ˆä¾‹: 199Ã—199, 256Ã—256ï¼‰ | å›ºå®šï¼ˆ64Ã—64æ¨å¥¨ï¼‰ | Coarseningï¼ˆå¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã§ç¸®å° |
| **æ™‚é–“æ§‹é€ ** | å„ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã‚¹ãƒ†ãƒƒãƒ— | é€£ç¶šæ™‚ç³»åˆ—é…åˆ— (n_timesteps, ...) | ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚é–“é †ã«ã‚¹ã‚¿ãƒƒã‚¯ |
| **æ•°å€¤ç²¾åº¦** | float64ï¼ˆç‰©ç†å˜ä½ï¼‰ | float32ï¼ˆæ­£è¦åŒ–æ¨å¥¨ï¼‰ | dtypeå¤‰æ› + æ­£è¦åŒ–ï¼ˆæ¨å¥¨ï¼‰ |
| **ã‚µãƒ³ãƒ—ãƒ«å˜ä½** | 1ã¤ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ | è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆè¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆï¼‰ | ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç­‰ã§åˆ†å‰² |
| **ä¿å­˜æ§‹é€ ** | è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ› | `file['x']` â†’ (n_samples, n_timesteps, 2, H, W) | HDF5ã¨ã—ã¦ä¿å­˜ (`create_hdf5_dataset`) |

### ğŸ” æ¨å¥¨å¤‰æ›ãƒ•ãƒ­ãƒ¼ï¼ˆæ¦‚è¦ï¼‰

```
IBPMå‡ºåŠ› (.plt)
   â†“
[1] parse_tecplot(): ASCII â†’ NumPyé…åˆ— (I, J, [x,y,u,v,vort])
   â†“
[2] extract_velocity(): u,v ã®2ãƒãƒ£ãƒ³ãƒãƒ«æŠ½å‡º â†’ (2,H,W)
   â†“
[3] coarsen(): å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã§ 256Ã—256 â†’ 64Ã—64
   â†“
[4] aggregate_timeseries(): ibpm*.plt ç¾¤ã‚’æ™‚ç³»åˆ—ã«çµåˆ (n_t, 2, 64, 64)
   â†“
[5] create_hdf5_dataset(): HDF5ã«ä¿å­˜ (train/valid/test)
   â†“
SDAå…¥åŠ›å½¢å¼å®Œæˆ â†’ (n_samples, n_timesteps, 2, 64, 64)
```

### âš™ï¸ SDAå­¦ç¿’ã¸ã®é©åˆæ€§

#### âœ… å½¢å¼äº’æ›
SDAã®`TrajectoryDataset`ã‚¯ãƒ©ã‚¹ãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«å®Œå…¨ä¸€è‡´:
```python
# SDAãŒæœŸå¾…ã™ã‚‹å½¢çŠ¶
(n_samples, window, n_channels, height, width)
# ä¾‹: (819, 64, 2, 64, 64)
```

#### âœ… å†…å®¹äº’æ›
Kolmogorov Flowã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§:
- é€Ÿåº¦å ´(u, v)ã®ã¿
- float32å‹
- ä½è§£åƒåº¦ï¼ˆ64Ã—64ï¼‰
- æ­£è¦åŒ–æ¸ˆã¿ï¼ˆæ¨å¥¨ï¼‰

#### âœ… å­¦ç¿’å¯èƒ½æ€§
- **çŸ­æ™‚é–“ç¢ºèª**: æœ€ä½é™ã®å­¦ç¿’ç¢ºèªãŒå¯èƒ½ï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«ã€window=64ï¼‰
- **æœ¬æ ¼å­¦ç¿’**: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«åŒ–ãŒå¿…è¦
  - è¤‡æ•°ã®IBPMå®Ÿé¨“ã‚’å®Ÿè¡Œ
  - ã¾ãŸã¯å˜ä¸€å®Ÿé¨“ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
  - æ¨å¥¨: æœ€ä½100ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Š

### âš ï¸ æ³¨æ„ç‚¹

1. **ã‚µãƒ³ãƒ—ãƒ«æ•°ã®ä¸è¶³**: å˜ä¸€IBPMå®Ÿé¨“ï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§ã¯éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ã‚ã‚Š
2. **æ™‚ç³»åˆ—é•·ã®ç¢ºä¿**: æœ€ä½ã§ã‚‚windowåˆ†ï¼ˆ64ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦
3. **æ­£è¦åŒ–ã®é‡è¦æ€§**: ç‰©ç†å˜ä½ã®ã¾ã¾å­¦ç¿’ã™ã‚‹ã¨åæŸã—ãªã„å¯èƒ½æ€§

---

## ãƒ‡ãƒ¼ã‚¿å‹ã®æ¯”è¼ƒ

### IBPMã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿

IBPMã¯`ibpm_output_YYYYMMDD_HHMMSS/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™:

#### 1. **ibpm.force** (æšåŠ›ãƒ»æŠ—åŠ›ãƒ‡ãƒ¼ã‚¿)
- **å½¢å¼**: ASCII ãƒ†ã‚­ã‚¹ãƒˆ
- **å†…å®¹**: æ™‚ç³»åˆ—ã®åŠ›å­¦ãƒ‡ãƒ¼ã‚¿
- **æ§‹é€ **:
  ```
  åˆ—0: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ç•ªå· (æ•´æ•°)
  åˆ—1: æ™‚åˆ» (æµ®å‹•å°æ•°ç‚¹)
  åˆ—2: xæ–¹å‘ã®åŠ› (Fx)
  åˆ—3: yæ–¹å‘ã®åŠ› (Fy)
  ```
- **ãƒ‡ãƒ¼ã‚¿å‹**: `float64`
- **ã‚µã‚¤ã‚ºä¾‹**: `(n_timesteps, 4)` where n_timesteps â‰ˆ 100-500

**ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿**:
```
    0 0.00000e+00 0.00000e+00 0.00000e+00
    1 2.00000e-02 6.96251e+00 1.39636e-14
    2 4.00000e-02 4.41590e+00 -3.08091e-15
```

#### 2. **ibpmXXXXX.plt** (Tecplotå¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«)
- **å½¢å¼**: ASCII Tecplot
- **å†…å®¹**: ç©ºé–“ã‚°ãƒªãƒƒãƒ‰ä¸Šã®æµä½“ç‰©ç†é‡
- **å¤‰æ•°**:
  - `x, y`: åº§æ¨™ (ç©ºé–“ä½ç½®)
  - `u, v`: é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«æˆåˆ† (x, yæ–¹å‘)
  - `Vorticity`: æ¸¦åº¦ (âˆ‚v/âˆ‚x - âˆ‚u/âˆ‚y)
- **ã‚°ãƒªãƒƒãƒ‰æ§‹é€ **: `ZONETYPE=Ordered`, `I Ã— J` æ ¼å­ç‚¹
- **ãƒ‡ãƒ¼ã‚¿å‹**: ASCIIå½¢å¼ã®`float32`/`float64`
- **ã‚µã‚¤ã‚ºä¾‹**: `(199, 199, 5)` â†’ 199Ã—199ã‚°ãƒªãƒƒãƒ‰ã€5å¤‰æ•°

**ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ **:
```
TITLE = "Test run, step00000"
VARIABLES = "x" "y" "u" "v" "Vorticity"
ZONE T="Rectangular zone"
I=199, J=199, K=1, ZONETYPE=Ordered
DATAPACKING=POINT
```

**ãƒ‡ãƒ¼ã‚¿è¡Œã®ä¾‹**:
```
-1.98000e+00 -1.98000e+00 1.00000e+00 0.00000e+00 0.00000e+00
-1.96000e+00 -1.98000e+00 1.00000e+00 0.00000e+00 0.00000e+00
```
å„è¡Œ: `x y u v vorticity`

#### 3. **ibpmXXXXX.bin** (ãƒã‚¤ãƒŠãƒªãƒªã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«)
- **å½¢å¼**: IBPMå›ºæœ‰ã®ãƒã‚¤ãƒŠãƒªå½¢å¼
- **å†…å®¹**: è¨ˆç®—ã®å®Œå…¨ãªçŠ¶æ…‹ï¼ˆé€Ÿåº¦å ´ã€åœ§åŠ›ã€å¢ƒç•ŒåŠ›ãªã©ï¼‰
- **ç”¨é€”**: è¨ˆç®—ã®å†é–‹ã€è©³ç´°è§£æ
- **ãƒ‡ãƒ¼ã‚¿å‹**: ãƒã‚¤ãƒŠãƒª (èª­ã¿å–ã‚Šã«IBPMãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦)
- **ã‚µã‚¤ã‚ºä¾‹**: ç´„1MB per timestep

---

### SDAã®æœŸå¾…ãƒ‡ãƒ¼ã‚¿å½¢å¼

SDAã¯ **HDF5å½¢å¼** ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

#### ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `train.h5`, `valid.h5`, `test.h5`

**HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ **:
```python
file['x']: numpy.ndarray
    shape: (n_samples, n_timesteps, n_channels, height, width)
    dtype: float32
```

#### å…·ä½“ä¾‹: Kolmogorov Flow

**Kolmogorovå®Ÿé¨“ã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶**:
```python
# generate.py:46-49
dset = f.create_dataset(
    'x',
    shape=(len(files), 64, 2, 64, 64),
    dtype=np.float32,
)
```

- **n_samples**: ã‚µãƒ³ãƒ—ãƒ«æ•° (ä¾‹: 819 for train, 102 for valid, 103 for test)
- **n_timesteps**: æ™‚ç³»åˆ—é•· (ä¾‹: 64)
- **n_channels**: ãƒãƒ£ãƒ³ãƒãƒ«æ•° (ä¾‹: 2 â†’ u, vã®2æˆåˆ†)
- **height, width**: ç©ºé–“è§£åƒåº¦ (ä¾‹: 64Ã—64)

**å®Ÿéš›ã®å½¢çŠ¶**: `(819, 64, 2, 64, 64)` â†’ ç´„64Ã—64Ã—2Ã—64Ã—819 â‰ˆ 326MB (float32)

#### ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆãƒ•ãƒ­ãƒ¼

SDAã®`experiments/kolmogorov/generate.py`ã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™:

```python
# 1. ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
x = chain.trajectory(x, length=128)  # 128ã‚¹ãƒ†ãƒƒãƒ—ã®trajectoryç”Ÿæˆ
x = x[64:]  # å¾ŒåŠ64ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½¿ç”¨ (ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å‰Šé™¤)

# 2. Coarsenå‡¦ç† (è§£åƒåº¦å‰Šæ¸›)
arr = KolmogorovFlow.coarsen(torch.from_numpy(x), 4)  # 256x256 â†’ 64x64

# 3. å‹å¤‰æ›ã¨HDF5ä¿å­˜
arr = arr.detach().cpu().numpy().astype(np.float32)
dset[i, ...] = arr  # shape: (64, 2, 64, 64)
```

---

## å·®åˆ†ã®è©³ç´°åˆ†æ

### 1. **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®é•ã„**

| é …ç›® | IBPM | SDA |
|------|------|-----|
| ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | ASCII Tecplot (.plt) / ãƒã‚¤ãƒŠãƒª (.bin) | HDF5 (.h5) |
| ãƒ‡ãƒ¼ã‚¿æ§‹é€  | ãƒ•ãƒ©ãƒƒãƒˆ (x, y, u, v, vort) | å¤šæ¬¡å…ƒé…åˆ— (samples, time, channels, H, W) |
| ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ | ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚¿ã‚¤ãƒˆãƒ«ã€å¤‰æ•°å | HDF5 attributes |
| åœ§ç¸® | ãªã— (ASCII) | HDF5åœ§ç¸®å¯èƒ½ |

### 2. **ç©ºé–“æ¬¡å…ƒã®é•ã„**

| é …ç›® | IBPM | SDA |
|------|------|-----|
| åº§æ¨™ç³» | (x, y) ã®ç‰©ç†åº§æ¨™ | æš—é»™çš„ãªã‚°ãƒªãƒƒãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (i, j) |
| ã‚°ãƒªãƒƒãƒ‰å½¢å¼ | `DATAPACKING=POINT` (å„ç‚¹ã«ã™ã¹ã¦ã®å¤‰æ•°) | ãƒãƒ£ãƒãƒ«åˆ†é›¢ `(C, H, W)` |
| æ ¼å­ç‚¹æ•° | ä»»æ„ (ä¾‹: 199Ã—199) | å›ºå®š (ä¾‹: 64Ã—64) |
| å¢ƒç•Œæ¡ä»¶ | å¤šæ§˜ (é æ–¹å ´ã€å‘¨æœŸå¢ƒç•Œãªã©) | å‘¨æœŸå¢ƒç•Œ (circular padding) |

### 3. **å¤‰æ•°ã®é•ã„**

| é …ç›® | IBPM | SDA (Kolmogorov) |
|------|------|------------------|
| å¤‰æ•° | x, y, u, v, vorticity | u, v (é€Ÿåº¦æˆåˆ†ã®ã¿) |
| ãƒãƒ£ãƒãƒ«æ•° | 5 (åº§æ¨™2 + é€Ÿåº¦2 + æ¸¦åº¦1) | 2 (é€Ÿåº¦æˆåˆ†ã®ã¿) |
| æ¸¦åº¦ã®æ‰±ã„ | ç›´æ¥å‡ºåŠ› | `KolmogorovFlow.vorticity()`ã§è¨ˆç®— |

### 4. **æ™‚ç³»åˆ—æ§‹é€ ã®é•ã„**

| é …ç›® | IBPM | SDA |
|------|------|-----|
| æ™‚ç³»åˆ—ä¿å­˜ | å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ« (ibpm00000.plt, ibpm00100.plt, ...) | å˜ä¸€HDF5å†…ã«é€£ç¶šé…åˆ— |
| ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ± | ãƒ•ã‚¡ã‚¤ãƒ«åã¨ibpm.force | é…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ |
| ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš” | è¨­å®šå¯èƒ½ (`-dt`, `-nsteps`) | å›ºå®š (generate.pyã§åˆ¶å¾¡) |

### 5. **ãƒ‡ãƒ¼ã‚¿å‹ã¨ç²¾åº¦**

| é …ç›® | IBPM | SDA |
|------|------|-----|
| æ•°å€¤å‹ | float64 (å€ç²¾åº¦) | float32 (å˜ç²¾åº¦) |
| æ­£è¦åŒ– | ãªã— (ç‰©ç†å˜ä½ãã®ã¾ã¾) | å¿…è¦ã«å¿œã˜ã¦æ­£è¦åŒ– |
| ã‚¹ã‚±ãƒ¼ãƒ« | O(1-10) ç¨‹åº¦ã®ç‰©ç†é‡ | O(-1 ~ 1) or standardized |

### 6. **è§£åƒåº¦ã¨Coarsening**

IBPMã¯é«˜è§£åƒåº¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ä¾‹: 256Ã—256) ã‚’å®Ÿè¡Œã—ã¾ã™ãŒã€SDAã®å­¦ç¿’ã§ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ä½è§£åƒåº¦ (64Ã—64) ã«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚

**Coarseningã®å®Ÿè£…**:
```python
# sda/mcs.py:340-347
@staticmethod
def coarsen(x: Tensor, r: int = 2) -> Tensor:
    *batch, h, w = x.shape
    x = x.reshape(*batch, h // r, r, w // r, r)
    x = x.mean(dim=(-3, -1))  # rÃ—rãƒ–ãƒ­ãƒƒã‚¯ã®å¹³å‡ã‚’å–ã‚‹
    return x
```

---

## å¤‰æ›å‡¦ç†ã®å®Ÿè£…

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
IBPMå‡ºåŠ›
    â†“
[1] Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ¼ã‚¹
    â†“
[2] ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    â†“
[3] åº§æ¨™ç³»ã‹ã‚‰é…åˆ—ã¸å¤‰æ›
    â†“
[4] ãƒãƒ£ãƒãƒ«åˆ†é›¢ (u, v)
    â†“
[5] è§£åƒåº¦èª¿æ•´ (Coarsening)
    â†“
[6] æ™‚ç³»åˆ—ã®é›†ç´„
    â†“
[7] æ­£è¦åŒ– (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    â†“
[8] HDF5å½¢å¼ã§ä¿å­˜
    â†“
SDAå…¥åŠ›ãƒ‡ãƒ¼ã‚¿
```

### å¿…è¦ãªå‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—

#### ã‚¹ãƒ†ãƒƒãƒ—1: Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ¼ã‚¹

**èª²é¡Œ**: ASCII Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

**è§£æ±ºç­–**:
```python
import numpy as np
import re

def parse_tecplot(file_path):
    """Tecplot .pltãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    with open(file_path, 'r') as f:
        lines = f.readlines()

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒ‘ãƒ¼ã‚¹
    header = {}
    for line in lines[:10]:
        if 'I=' in line:
            match = re.search(r'I=(\d+),\s*J=(\d+)', line)
            if match:
                header['I'] = int(match.group(1))
                header['J'] = int(match.group(2))
        elif 'VARIABLES' in line:
            # VARIABLES = "x" "y" "u" "v" "Vorticity"
            vars_match = re.findall(r'"([^"]+)"', line)
            header['variables'] = vars_match

    # ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã®æŠ½å‡º (ãƒ˜ãƒƒãƒ€ãƒ¼å¾Œã‹ã‚‰)
    data_start = 0
    for i, line in enumerate(lines):
        if 'DATAPACKING' in line:
            data_start = i + 1
            break

    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    data_lines = lines[data_start:]
    data = []
    for line in data_lines:
        if line.strip():
            values = list(map(float, line.split()))
            data.append(values)

    data = np.array(data)

    # ã‚°ãƒªãƒƒãƒ‰å½¢çŠ¶ã«æ•´å½¢
    I, J = header['I'], header['J']
    assert len(data) == I * J, f"Data length mismatch: {len(data)} vs {I*J}"

    # (I*J, n_vars) â†’ (J, I, n_vars) â†’ (I, J, n_vars)
    data_grid = data.reshape(J, I, -1).transpose(1, 0, 2)

    return data_grid, header
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: é€Ÿåº¦æˆåˆ†ã®æŠ½å‡ºã¨ãƒãƒ£ãƒãƒ«åˆ†é›¢

**èª²é¡Œ**: (H, W, 5) â†’ (2, H, W)

```python
def extract_velocity(data_grid, header):
    """é€Ÿåº¦æˆåˆ† (u, v) ã‚’æŠ½å‡º"""
    variables = header['variables']

    # å¤‰æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    u_idx = variables.index('u')
    v_idx = variables.index('v')

    # (H, W, n_vars) â†’ (H, W, 2) â†’ (2, H, W)
    u = data_grid[:, :, u_idx]
    v = data_grid[:, :, v_idx]

    velocity = np.stack([u, v], axis=0)  # (2, H, W)

    return velocity
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: è§£åƒåº¦èª¿æ•´ (Coarsening)

**èª²é¡Œ**: 256Ã—256 â†’ 64Ã—64

```python
import torch

def coarsen_numpy(x, r=4):
    """NumPyé…åˆ—ã‚’Coarsenã™ã‚‹ (rÃ—rãƒ–ãƒ­ãƒƒã‚¯ã®å¹³å‡)"""
    if isinstance(x, np.ndarray):
        x = torch.from_numpy(x)

    *batch, h, w = x.shape
    assert h % r == 0 and w % r == 0, f"Size {h}x{w} not divisible by {r}"

    x = x.reshape(*batch, h // r, r, w // r, r)
    x = x.mean(dim=(-3, -1))

    return x.numpy()
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„

**èª²é¡Œ**: è¤‡æ•°ã®.pltãƒ•ã‚¡ã‚¤ãƒ« â†’ å˜ä¸€ã®æ™‚ç³»åˆ—é…åˆ—

```python
from pathlib import Path
import h5py

def aggregate_timeseries(output_dir, coarsen_factor=4):
    """IBPMã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„"""
    output_path = Path(output_dir)

    # .pltãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚åˆ»é †ã«ã‚½ãƒ¼ãƒˆ
    plt_files = sorted(output_path.glob('ibpm*.plt'))

    timeseries = []

    for plt_file in plt_files:
        # ãƒ‘ãƒ¼ã‚¹
        data_grid, header = parse_tecplot(plt_file)

        # é€Ÿåº¦æˆåˆ†ã‚’æŠ½å‡º (2, H, W)
        velocity = extract_velocity(data_grid, header)

        # Coarsen
        velocity_coarse = coarsen_numpy(velocity, r=coarsen_factor)

        timeseries.append(velocity_coarse)

    # (n_timesteps, 2, H, W)
    timeseries = np.stack(timeseries, axis=0).astype(np.float32)

    return timeseries
```

#### ã‚¹ãƒ†ãƒƒãƒ—5: HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

**èª²é¡Œ**: SDAå½¢å¼ã®HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ

```python
def create_hdf5_dataset(
    timeseries_list,
    output_file,
    train_ratio=0.8,
    valid_ratio=0.1
):
    """è¤‡æ•°ã®æ™‚ç³»åˆ—ã‹ã‚‰HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""

    n_samples = len(timeseries_list)
    n_train = int(n_samples * train_ratio)
    n_valid = int(n_samples * valid_ratio)

    splits = {
        'train': timeseries_list[:n_train],
        'valid': timeseries_list[n_train:n_train+n_valid],
        'test': timeseries_list[n_train+n_valid:],
    }

    for split_name, data_list in splits.items():
        with h5py.File(f'{output_file}_{split_name}.h5', 'w') as f:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
            if len(data_list) > 0:
                sample_shape = data_list[0].shape
                full_shape = (len(data_list),) + sample_shape

                dset = f.create_dataset(
                    'x',
                    shape=full_shape,
                    dtype=np.float32,
                    compression='gzip',  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: åœ§ç¸®
                )

                for i, data in enumerate(data_list):
                    dset[i] = data

                print(f"{split_name}: {dset.shape}")
```

---

## å®Ÿè£…ä¾‹

### å®Œå…¨ãªå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
#!/usr/bin/env python
"""
IBPMå‡ºåŠ›ã‚’SDAå½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python convert_ibpm_to_sda.py \
        --input /path/to/ibpm_output_20251014_123123 \
        --output /path/to/sda/data \
        --coarsen 4 \
        --window 64
"""

import argparse
import numpy as np
import h5py
import torch
import re
from pathlib import Path
from tqdm import tqdm


def parse_tecplot(file_path):
    """Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹"""
    with open(file_path, 'r') as f:
        lines = f.readlines()

    # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
    header = {}
    data_start_idx = 0

    for i, line in enumerate(lines):
        if 'I=' in line and 'J=' in line:
            match = re.search(r'I=(\d+),\s*J=(\d+)', line)
            if match:
                header['I'] = int(match.group(1))
                header['J'] = int(match.group(2))

        if 'VARIABLES' in line:
            vars_match = re.findall(r'"([^"]+)"', line)
            header['variables'] = vars_match

        if 'DATAPACKING' in line:
            data_start_idx = i + 1
            break

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_lines = lines[data_start_idx:]
    data = []
    for line in data_lines:
        if line.strip():
            values = list(map(float, line.split()))
            if len(values) == len(header['variables']):
                data.append(values)

    data = np.array(data)

    # ã‚°ãƒªãƒƒãƒ‰å½¢çŠ¶ã«æ•´å½¢
    I, J = header['I'], header['J']
    data_grid = data.reshape(J, I, -1).transpose(1, 0, 2)

    return data_grid, header


def extract_velocity(data_grid, header):
    """é€Ÿåº¦å ´ (u, v) ã‚’æŠ½å‡º"""
    variables = header['variables']

    u_idx = variables.index('u')
    v_idx = variables.index('v')

    u = data_grid[:, :, u_idx]
    v = data_grid[:, :, v_idx]

    velocity = np.stack([u, v], axis=0)  # (2, H, W)

    return velocity


def coarsen(x, r):
    """ç©ºé–“è§£åƒåº¦ã‚’å‰Šæ¸› (rÃ—rå¹³å‡)"""
    x = torch.from_numpy(x) if isinstance(x, np.ndarray) else x

    *batch, h, w = x.shape
    x = x.reshape(*batch, h // r, r, w // r, r)
    x = x.mean(dim=(-3, -1))

    return x.numpy()


def process_ibpm_output(
    input_dir,
    coarsen_factor=4,
    window=64,
):
    """IBPMå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†"""
    input_path = Path(input_dir)

    # .pltãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    plt_files = sorted(input_path.glob('ibpm*.plt'))

    print(f"Found {len(plt_files)} timesteps in {input_dir}")

    if len(plt_files) < window:
        raise ValueError(
            f"Not enough timesteps: {len(plt_files)} < {window}"
        )

    timeseries = []

    for plt_file in tqdm(plt_files, desc="Parsing"):
        data_grid, header = parse_tecplot(plt_file)
        velocity = extract_velocity(data_grid, header)

        if coarsen_factor > 1:
            velocity = coarsen(velocity, coarsen_factor)

        timeseries.append(velocity)

    # (n_timesteps, 2, H, W)
    timeseries = np.stack(timeseries, axis=0).astype(np.float32)

    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«åˆ‡ã‚Šå‡ºã—
    if len(timeseries) > window:
        # å¾ŒåŠã‚’ä½¿ç”¨ (åˆæœŸéæ¸¡ã‚’é™¤ã)
        timeseries = timeseries[-window:]

    return timeseries


def create_sda_dataset(
    timeseries_list,
    output_dir,
    train_ratio=0.8,
    valid_ratio=0.1,
):
    """SDAå½¢å¼ã®HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    n_samples = len(timeseries_list)
    n_train = int(n_samples * train_ratio)
    n_valid = int(n_samples * valid_ratio)

    splits = {
        'train': timeseries_list[:n_train],
        'valid': timeseries_list[n_train:n_train+n_valid],
        'test': timeseries_list[n_train+n_valid:],
    }

    for split_name, data_list in splits.items():
        if len(data_list) == 0:
            print(f"Warning: {split_name} split is empty")
            continue

        output_file = output_path / f'{split_name}.h5'

        with h5py.File(output_file, 'w') as f:
            sample_shape = data_list[0].shape
            full_shape = (len(data_list),) + sample_shape

            dset = f.create_dataset(
                'x',
                shape=full_shape,
                dtype=np.float32,
                compression='gzip',
                compression_opts=4,
            )

            for i, data in enumerate(data_list):
                dset[i] = data

            print(f"{split_name}: {dset.shape} -> {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description="Convert IBPM output to SDA HDF5 format"
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='Path to IBPM output directory'
    )
    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='Output directory for HDF5 files'
    )
    parser.add_argument(
        '--coarsen',
        type=int,
        default=4,
        help='Coarsening factor (default: 4)'
    )
    parser.add_argument(
        '--window',
        type=int,
        default=64,
        help='Time window size (default: 64)'
    )
    parser.add_argument(
        '--train-ratio',
        type=float,
        default=0.8,
        help='Training split ratio (default: 0.8)'
    )
    parser.add_argument(
        '--valid-ratio',
        type=float,
        default=0.1,
        help='Validation split ratio (default: 0.1)'
    )

    args = parser.parse_args()

    # IBPMå‡ºåŠ›ã‚’å‡¦ç†
    print(f"Processing IBPM output from: {args.input}")
    timeseries = process_ibpm_output(
        args.input,
        coarsen_factor=args.coarsen,
        window=args.window,
    )

    print(f"Timeseries shape: {timeseries.shape}")

    # å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    # è¤‡æ•°ã®IBPMå®Ÿé¨“ãŒã‚ã‚‹å ´åˆã¯ã€ã“ã“ã§ãƒªã‚¹ãƒˆã«è¿½åŠ 
    timeseries_list = [timeseries]

    # HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
    print(f"Creating SDA dataset in: {args.output}")
    create_sda_dataset(
        timeseries_list,
        args.output,
        train_ratio=args.train_ratio,
        valid_ratio=args.valid_ratio,
    )

    print("Conversion completed successfully!")


if __name__ == '__main__':
    main()
```

### ä½¿ç”¨ä¾‹

```bash
# åŸºæœ¬çš„ãªä½¿ç”¨æ³•
python convert_ibpm_to_sda.py \
    --input /workspace/ibpm_output_20251014_123123 \
    --output /workspace/sda/experiments/ibpm/data \
    --coarsen 4 \
    --window 64

# è¤‡æ•°ã®å®Ÿé¨“ã‚’å‡¦ç†
for dir in ibpm_output_*/; do
    python convert_ibpm_to_sda.py \
        --input "$dir" \
        --output /workspace/sda/experiments/ibpm/data \
        --coarsen 4 \
        --window 64
done
```

### å¤‰æ›å¾Œã®ç¢ºèª

```python
import h5py
import numpy as np

# HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
with h5py.File('train.h5', 'r') as f:
    print("Keys:", list(f.keys()))
    print("Shape:", f['x'].shape)
    print("Dtype:", f['x'].dtype)
    print("Min/Max:", f['x'][:].min(), f['x'][:].max())

    # ã‚µãƒ³ãƒ—ãƒ«ã‚’å¯è¦–åŒ–
    sample = f['x'][0]  # (n_timesteps, 2, H, W)
    print(f"Sample shape: {sample.shape}")
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: ãƒ‘ãƒ¼ã‚¹æ™‚ã®ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**:
```
IndexError: list index out of range
```

**åŸå› **: Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæƒ³å®šã¨ç•°ãªã‚‹

**è§£æ±ºç­–**:
- ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œæ•°ã‚’ç¢ºèª
- `DATAPACKING`ã®ä½ç½®ã‚’èª¿æ•´
- ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã§`header`ã¨`data_start_idx`ã‚’ç¢ºèª

```python
# ãƒ‡ãƒãƒƒã‚°ç”¨
print(f"Header: {header}")
print(f"Data start: {data_start_idx}")
print(f"First data line: {lines[data_start_idx]}")
```

### å•é¡Œ2: å½¢çŠ¶ã®ä¸ä¸€è‡´

**ç—‡çŠ¶**:
```
AssertionError: Data length mismatch: 39601 vs 39600
```

**åŸå› **: ã‚°ãƒªãƒƒãƒ‰ç‚¹æ•°ã®è¨ˆç®—ãƒŸã‚¹ã€ã¾ãŸã¯ç©ºè¡Œã®æ··å…¥

**è§£æ±ºç­–**:
- ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
- `I Ã— J`ã®ç©ã‚’ç¢ºèª

```python
# ä¿®æ­£ä¾‹
for line in data_lines:
    if line.strip() and not line.startswith('#'):  # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚‚é™¤å¤–
        values = list(map(float, line.split()))
        if len(values) == len(header['variables']):  # æ­£ã—ã„åˆ—æ•°ã®ã¿
            data.append(values)
```

### å•é¡Œ3: ãƒ¡ãƒ¢ãƒªä¸è¶³

**ç—‡çŠ¶**:
```
MemoryError: Unable to allocate array
```

**åŸå› **: é«˜è§£åƒåº¦ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚“ã§ã„ã‚‹

**è§£æ±ºç­–**:
- Coarseningã‚’æ—©ã‚ã«é©ç”¨
- ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§å‡¦ç†
- HDF5ã®åœ§ç¸®ã‚’æœ‰åŠ¹åŒ–

```python
# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå‡¦ç†
def process_in_chunks(plt_files, chunk_size=10):
    for i in range(0, len(plt_files), chunk_size):
        chunk = plt_files[i:i+chunk_size]
        yield process_chunk(chunk)
```

### å•é¡Œ4: æ­£è¦åŒ–ã®å¿…è¦æ€§

**ç—‡çŠ¶**: å­¦ç¿’ãŒåæŸã—ãªã„ã€loss ãŒ NaN

**åŸå› **: é€Ÿåº¦å ´ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒSDAã®æœŸå¾…ç¯„å›²å¤–

**è§£æ±ºç­–**: ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–

```python
def normalize_velocity(velocity, method='standardize'):
    """é€Ÿåº¦å ´ã‚’æ­£è¦åŒ–"""
    if method == 'standardize':
        # å¹³å‡0ã€æ¨™æº–åå·®1
        mean = velocity.mean()
        std = velocity.std()
        return (velocity - mean) / (std + 1e-8)

    elif method == 'minmax':
        # [0, 1] ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        vmin = velocity.min()
        vmax = velocity.max()
        return (velocity - vmin) / (vmax - vmin + 1e-8)

    elif method == 'clip':
        # [-3, 3] ã«ã‚¯ãƒªãƒƒãƒ—
        return np.clip(velocity, -3, 3) / 3
```

### å•é¡Œ5: æ™‚ç³»åˆ—é•·ã®ä¸è¶³

**ç—‡çŠ¶**:
```
ValueError: Not enough timesteps: 50 < 64
```

**åŸå› **: IBPMå®Ÿè¡Œæ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒä¸è¶³

**è§£æ±ºç­–**:
- IBPMã®`-nsteps`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å¢—ã‚„ã™
- ã¾ãŸã¯`window`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸›ã‚‰ã™

```bash
# ã‚ˆã‚Šé•·ã„æ™‚ç³»åˆ—ã‚’ç”Ÿæˆ
ibpm -geom cylinder.geom -nsteps 500 -dt 0.01
```

---

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

### æ¨å¥¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

IBPMãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SDAã¸ã®å¤‰æ›ã‚’è¡Œã†éš›ã«ã¯ã€ä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã“ã®æ§‹æˆã«ã‚ˆã‚Šã€**ãƒ‡ãƒ¼ã‚¿ã®è²¬ä»»åˆ†é›¢**ã€**ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**ã€**Kolmogorovå®Ÿé¨“ã¨ã®ä¸€è²«æ€§**ãŒç¢ºä¿ã•ã‚Œã¾ã™ã€‚

```
/workspace/
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”‚
â”œâ”€â”€ docs/                           # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ IBPM.md
â”‚   â”œâ”€â”€ IBPM_SDA_implementation_tasks.md
â”‚   â”œâ”€â”€ IBPM_to_SDA_data_conversion.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                           # ã™ã¹ã¦ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ ibpm/                       # IBPMç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆTecplotç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ ibpm_output_20251014_123123/
â”‚   â”‚       â”œâ”€â”€ ibpm.cmd
â”‚   â”‚       â”œâ”€â”€ ibpm.force
â”‚   â”‚       â”œâ”€â”€ ibpm00000.plt
â”‚   â”‚       â”œâ”€â”€ ibpm00000.bin
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ kolmogorov_flow/            # Kolmogorovç”Ÿãƒ‡ãƒ¼ã‚¿
â”‚       â”œâ”€â”€ x_000000.npy
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/                        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ convert_ibpm_to_sda.py     # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆIBPMã‹ã‚‰SDAå½¢å¼ã¸ï¼‰
â”‚   â”œâ”€â”€ verify_data.py              # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
â”‚   â”œâ”€â”€ setup.sh
â”‚   â””â”€â”€ slurm/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ sda/                            # SDAãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æœ¬ä½“
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ setup.py
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ environment.yml
â”‚   â”‚
â”‚   â”œâ”€â”€ sda/                        # SDAã‚³ã‚¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mcs.py
â”‚   â”‚   â”œâ”€â”€ nn.py
â”‚   â”‚   â”œâ”€â”€ score.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â””â”€â”€ experiments/                # å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ kolmogorov/             # Kolmogorov Flowå®Ÿé¨“
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ utils.py
â”‚       â”‚   â”œâ”€â”€ generate.py
â”‚       â”‚   â”œâ”€â”€ train.py
â”‚       â”‚   â”œâ”€â”€ eval.py
â”‚       â”‚   â””â”€â”€ data/               # Kolmogorovå¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆHDF5ï¼‰
â”‚       â”‚       â”œâ”€â”€ train.h5
â”‚       â”‚       â”œâ”€â”€ valid.h5
â”‚       â”‚       â””â”€â”€ test.h5
â”‚       â”‚
â”‚       â”œâ”€â”€ lorenz/                 # Lorenzå®Ÿé¨“
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ utils.py
â”‚       â”‚   â”œâ”€â”€ generate.py
â”‚       â”‚   â”œâ”€â”€ train.py
â”‚       â”‚   â””â”€â”€ data/
â”‚       â”‚
â”‚       â””â”€â”€ ibpm/                   # IBPMå®Ÿé¨“ï¼ˆæ–°è¦ï¼‰â˜…
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ utils.py            # IBPMç”¨ã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆå¿…è¦æ™‚ï¼‰
â”‚           â”œâ”€â”€ train.py            # IBPMç”¨å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå¿…è¦æ™‚ï¼‰
â”‚           â”œâ”€â”€ README.md           # IBPMå®Ÿé¨“ã®èª¬æ˜
â”‚           â””â”€â”€ data/               # IBPMå¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆHDF5ï¼‰â˜…
â”‚               â”œâ”€â”€ train.h5
â”‚               â”œâ”€â”€ valid.h5
â”‚               â””â”€â”€ test.h5
â”‚
â”œâ”€â”€ runs/                           # å­¦ç¿’çµæœï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç­‰ï¼‰
â”‚   â”œâ”€â”€ northern-forest-6_x70kk1jw/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/                        # å®Ÿé¨“çµæœï¼ˆç”»åƒã€ãƒ­ã‚°ç­‰ï¼‰
â”‚   â”œâ”€â”€ imgs/
â”‚   â””â”€â”€ slurm/
â”‚
â”œâ”€â”€ wandb/                          # Weights & Biases ãƒ­ã‚°
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ infra/                          # ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®š
    â””â”€â”€ slurm/
        â”œâ”€â”€ bin/
        â””â”€â”€ config/
```

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã®ãƒ¡ãƒªãƒƒãƒˆ

#### 1. **æ˜ç¢ºãªè²¬ä»»åˆ†é›¢**
- `data/`: ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
- `scripts/`: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»å¤‰æ›ãƒ„ãƒ¼ãƒ«
- `sda/experiments/*/data/`: å®Ÿé¨“ç”¨ã®å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
- `runs/`: å­¦ç¿’çµæœ
- `results/`: æœ€çµ‚æˆæœç‰©

#### 2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**
- æ–°ã—ã„å®Ÿé¨“ï¼ˆä¾‹: `experiments/cylinder/`ï¼‰ã‚’è¿½åŠ ã—ã‚„ã™ã„
- è¤‡æ•°ã®IBPMå®Ÿé¨“ã‚’ç®¡ç†ã—ã‚„ã™ã„

#### 3. **ä¸€è²«æ€§**
- Kolmogorovå®Ÿé¨“ã¨åŒã˜æ§‹é€ 
- SDAãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¦ç´„ã«å¾“ã†

#### 4. **ç§»æ¤æ€§**
- ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒ`scripts/`ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹
- ç›¸å¯¾ãƒ‘ã‚¹ã§ã¯ãªãæ˜ç¤ºçš„ãªãƒ‘ã‚¹ã‚’ä½¿ç”¨

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ™‚ã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’æ•´å‚™ã—ã¾ã™:

```bash
# 1. IBPMå®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆå¿…é ˆï¼‰
mkdir -p /workspace/sda/experiments/ibpm/data
touch /workspace/sda/experiments/ibpm/__init__.py

# 2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã¨ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ï¼ˆæ¨å¥¨ï¼‰
mkdir -p /workspace/scripts

# 3. IBPMãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
mkdir -p /workspace/data/ibpm
```

### ãƒ‘ã‚¹æŒ‡å®šã®ä¾‹

ã“ã®æ§‹æˆã«ã‚ˆã‚Šã€ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã®ãƒ‘ã‚¹æŒ‡å®šã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™:

```bash
# å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œä¾‹
python scripts/convert_ibpm_to_sda.py \
  --input /workspace/data/ibpm/ibpm_output_20251014_123123 \
  --output /workspace/sda/experiments/ibpm/data

# ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œä¾‹
python scripts/verify_data.py \
  --data /workspace/sda/experiments/ibpm/data/train.h5
```

---

## æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

#### ãƒ•ã‚§ãƒ¼ã‚º1: IBPMå®Ÿé¨“ã®æº–å‚™ã¨å®Ÿè¡Œ

```bash
# 1. IBPMã§è¤‡æ•°ã®å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆç•°ãªã‚‹åˆæœŸæ¡ä»¶ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
cd /workspace/ibpm/examples

# å®Ÿé¨“1: æ¨™æº–è¨­å®š
../build/ibpm -geom cylinder.geom -Re 100 -nsteps 300 -dt 0.01

# å®Ÿé¨“2: ãƒ¬ã‚¤ãƒãƒ«ã‚ºæ•°ã‚’å¤‰æ›´
../build/ibpm -geom cylinder.geom -Re 150 -nsteps 300 -dt 0.01

# å®Ÿé¨“3: ã‚ˆã‚Šé•·æ™‚é–“
../build/ibpm -geom cylinder.geom -Re 100 -nsteps 500 -dt 0.01

# å‡ºåŠ›ã‚’æ•´ç†
mkdir -p /workspace/ibpm_experiments
mv ibpm_output_* /workspace/ibpm_experiments/
```

**æ¨å¥¨è¨­å®š**:
- `-nsteps`: æœ€ä½200ä»¥ä¸Šï¼ˆwindow=64ã‚’ç¢ºä¿ã—ã€åˆæœŸéæ¸¡ã‚’é™¤å¤–ã™ã‚‹ãŸã‚ï¼‰
- `-dt`: 0.01 ~ 0.02ï¼ˆæ™‚é–“è§£åƒåº¦ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
- `-Re`: 100 ~ 200ï¼ˆç‰©ç†çš„ã«èˆˆå‘³æ·±ã„ç¯„å›²ï¼‰

#### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ‡ãƒ¼ã‚¿å¤‰æ›

```bash
# 2. å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œï¼ˆå˜ä¸€å®Ÿé¨“ã®å ´åˆï¼‰
python scripts/convert_ibpm_to_sda.py \
    --input /workspace/data/ibpm/ibpm_output_20251014_123123 \
    --output /workspace/sda/experiments/ibpm/data \
    --coarsen 4 \
    --window 64 \
    --stride 8

# 3. è¤‡æ•°å®Ÿé¨“ã‚’ä¸€æ‹¬å¤‰æ›ï¼ˆè¤‡æ•°å®Ÿé¨“ãŒã‚ã‚‹å ´åˆï¼‰
for dir in /workspace/data/ibpm/ibpm_output_*/; do
    python scripts/convert_ibpm_to_sda.py \
        --input "$dir" \
        --output /workspace/sda/experiments/ibpm/data \
        --coarsen 4 \
        --window 64 \
        --stride 8
done
```

**æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `--coarsen 4`: 256Ã—256 â†’ 64Ã—64ï¼ˆKolmogorovã¨åŒã˜ï¼‰
- `--window 64`: SDAã®æ¨™æº–æ™‚ç³»åˆ—é•·
- `--stride 8`: ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆå°ã•ã„ã»ã©ã‚µãƒ³ãƒ—ãƒ«æ•°å¢—åŠ ï¼‰
- `--train-ratio 0.7`: 70% è¨“ç·´ã€15% æ¤œè¨¼ã€15% ãƒ†ã‚¹ãƒˆ

#### ãƒ•ã‚§ãƒ¼ã‚º3: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼

```python
# 4. HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
import h5py
import numpy as np
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with h5py.File('/workspace/sda/experiments/ibpm/data/train.h5', 'r') as f:
    data = f['x'][:]
    print(f"Shape: {data.shape}")
    print(f"Dtype: {data.dtype}")
    print(f"Range: [{data.min():.3f}, {data.max():.3f}]")
    print(f"Mean: {data.mean():.3f}, Std: {data.std():.3f}")

    # ã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–
    sample = data[0, 0]  # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—
    u, v = sample[0], sample[1]

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(u, cmap='RdBu_r')
    axes[0].set_title('u velocity')
    axes[1].imshow(v, cmap='RdBu_r')
    axes[1].set_title('v velocity')

    # æ¸¦åº¦ã‚’è¨ˆç®—
    vorticity = np.gradient(v, axis=0) - np.gradient(u, axis=1)
    axes[2].imshow(vorticity, cmap='RdBu_r')
    axes[2].set_title('Vorticity')

    plt.savefig('ibpm_data_check.png')
    print("Saved visualization to ibpm_data_check.png")
```

#### ãƒ•ã‚§ãƒ¼ã‚º4: SDAå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ

```bash
# 5. IBPMå®Ÿé¨“ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir -p sda/experiments/ibpm
cd sda/experiments/ibpm
```

```python
# 6. utils.py ã‚’ä½œæˆ
# sda/experiments/ibpm/utils.py
import os
from pathlib import Path
from sda.mcs import *
from sda.score import *
from sda.utils import *

if 'SCRATCH' in os.environ:
    SCRATCH = os.environ['SCRATCH']
    PATH = Path(SCRATCH) / 'sda/ibpm'
else:
    PATH = Path('.')

PATH.mkdir(parents=True, exist_ok=True)


def make_score(
    window: int = 5,
    embedding: int = 64,
    hidden_channels: Sequence[int] = (96, 192, 384),
    hidden_blocks: Sequence[int] = (3, 3, 3),
    kernel_size: int = 3,
    activation: str = 'SiLU',
    **absorb,
) -> nn.Module:
    score = MCScoreNet(2, order=window // 2)
    score.kernel = ScoreUNet(
        channels=window * 2,
        embedding=embedding,
        hidden_channels=hidden_channels,
        hidden_blocks=hidden_blocks,
        kernel_size=kernel_size,
        activation=ACTIVATIONS[activation],
        spatial=2,
        padding_mode='circular',  # å‘¨æœŸå¢ƒç•Œæ¡ä»¶
    )
    return score


def load_score(file: Path, device: str = 'cpu', **kwargs) -> nn.Module:
    state = torch.load(file, map_location=device)
    config = load_config(file.parent)
    config.update(kwargs)
    score = make_score(**config)
    score.load_state_dict(state)
    return score
```

```python
# 7. train.py ã‚’ä½œæˆ
# sda/experiments/ibpm/train.py
#!/usr/bin/env python

import wandb
from dawgz import job, schedule

from sda.mcs import *
from sda.score import *
from sda.utils import *
from .utils import *

CONFIG = {
    # Architecture
    'window': 5,
    'embedding': 64,
    'hidden_channels': (96, 192, 384),
    'hidden_blocks': (3, 3, 3),
    'kernel_size': 3,
    'activation': 'SiLU',
    # Training
    'epochs': 2048,
    'batch_size': 16,  # å°ã•ã‚ã«è¨­å®šï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„å ´åˆï¼‰
    'optimizer': 'AdamW',
    'learning_rate': 1e-4,
    'weight_decay': 1e-3,
    'scheduler': 'cosine',
}


@job(array=3, cpus=4, gpus=1, ram='16GB', time='24:00:00')
def train(i: int):
    run = wandb.init(project='sda-ibpm', config=CONFIG)
    runpath = PATH / f'runs/{run.name}_{run.id}'
    runpath.mkdir(parents=True, exist_ok=True)

    save_config(CONFIG, runpath)

    # Network
    window = CONFIG['window']
    score = make_score(**CONFIG)
    shape = torch.Size((window * 2, 64, 64))
    sde = VPSDE(score.kernel, shape=shape).cuda()

    # Data
    trainset = TrajectoryDataset(
        PATH / 'data/train.h5',
        window=window,
        flatten=True
    )
    validset = TrajectoryDataset(
        PATH / 'data/valid.h5',
        window=window,
        flatten=True
    )

    print(f"Train samples: {len(trainset)}")
    print(f"Valid samples: {len(validset)}")

    # Training
    generator = loop(
        sde,
        trainset,
        validset,
        device='cuda',
        **CONFIG,
    )

    for loss_train, loss_valid, lr in generator:
        run.log({
            'loss_train': loss_train,
            'loss_valid': loss_valid,
            'lr': lr,
        })

    # Save
    torch.save(score.state_dict(), runpath / 'state.pth')

    # Sample generation
    x = sde.sample(torch.Size([4]), steps=64).cpu()
    x = x.unflatten(1, (-1, 2))

    # æ¸¦åº¦ã‚’è¨ˆç®—ã—ã¦å¯è¦–åŒ–
    vorticity = []
    for sample in x:
        w = torch.gradient(sample[:, 1], dim=1)[0] - \
            torch.gradient(sample[:, 0], dim=2)[0]
        vorticity.append(w)
    vorticity = torch.stack(vorticity)

    # ç°¡æ˜“å¯è¦–åŒ–ï¼ˆKolmogorovç”¨ã®drawé–¢æ•°ãŒãªã„å ´åˆï¼‰
    import matplotlib.pyplot as plt
    fig, axes = plt.subplots(2, 2, figsize=(10, 10))
    for idx, ax in enumerate(axes.flat):
        ax.imshow(vorticity[idx, 0].numpy(), cmap='RdBu_r')
        ax.axis('off')
    plt.tight_layout()
    plt.savefig(runpath / 'samples.png')
    run.log({'samples': wandb.Image(str(runpath / 'samples.png'))})

    run.finish()


if __name__ == '__main__':
    schedule(
        train,
        name='IBPM Training',
        backend='slurm',
        export='ALL',
        env=['export WANDB_SILENT=true'],
    )
```

#### ãƒ•ã‚§ãƒ¼ã‚º5: å­¦ç¿’å®Ÿè¡Œ

```bash
# 8. å­¦ç¿’ã‚’é–‹å§‹
cd /workspace/sda/experiments/ibpm
python train.py
```

### ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹çµæœ

#### å­¦ç¿’åˆæœŸï¼ˆepoch 0-100ï¼‰
- Loss: é«˜ã„ï¼ˆ~10-100ï¼‰
- é€Ÿåº¦å ´ã®å¤§ã¾ã‹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’

#### å­¦ç¿’ä¸­æœŸï¼ˆepoch 100-500ï¼‰
- Loss: å®‰å®šåŒ–ï¼ˆ~1-10ï¼‰
- å††æŸ±å‘¨ã‚Šã®æµã‚Œã®ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‚’ç²å¾—

#### å­¦ç¿’å¾ŒæœŸï¼ˆepoch 500-2000ï¼‰
- Loss: åæŸï¼ˆ~0.1-1ï¼‰
- è©³ç´°ãªæ¸¦æ§‹é€ ã®å†ç¾

### ğŸ¯ æˆåŠŸã®æŒ‡æ¨™

1. **LossåæŸ**: validation lossãŒå®‰å®šã—ã¦ä¸‹é™
2. **ã‚µãƒ³ãƒ—ãƒ«å“è³ª**: ç”Ÿæˆã•ã‚ŒãŸé€Ÿåº¦å ´ãŒç‰©ç†çš„ã«å¦¥å½“
3. **æ¸¦åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³**: ã‚«ãƒ«ãƒãƒ³æ¸¦åˆ—ãªã©ã®ç‰¹å¾´çš„æ§‹é€ ã‚’å†ç¾

---

## ã¾ã¨ã‚

### å¤‰æ›ã®è¦ç‚¹

1. **Tecplotãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ¼ã‚¹**: ASCIIå½¢å¼ã‹ã‚‰æ•°å€¤é…åˆ—ã¸
2. **é€Ÿåº¦æˆåˆ†ã®æŠ½å‡º**: (H, W, 5) â†’ (2, H, W)
3. **è§£åƒåº¦èª¿æ•´**: 256Ã—256 â†’ 64Ã—64 (Coarsening)
4. **æ™‚ç³»åˆ—ã®é›†ç´„**: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ« â†’ å˜ä¸€é…åˆ—
5. **HDF5å½¢å¼ã§ã®ä¿å­˜**: SDAãŒèª­ã¿è¾¼ã‚ã‚‹å½¢å¼

### ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®é·ç§»

```
IBPM: ibpm00000.plt (ASCII)
  â†“ parse_tecplot()
(199, 199, 5) float64  [x, y, u, v, vorticity]
  â†“ extract_velocity()
(2, 199, 199) float64  [u, v]
  â†“ coarsen(r=3)
(2, 66, 66) float64
  â†“ aggregate_timeseries()
(n_timesteps, 2, 66, 66) float32
  â†“ create_hdf5_dataset()
SDA: train.h5
  Dataset 'x': (n_samples, n_timesteps, 2, 66, 66) float32
```

### æ¨å¥¨è¨­å®š

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ¨å¥¨å€¤ | ç†ç”± |
|-----------|--------|------|
| IBPM `-nsteps` | 200-500 | ååˆ†ãªæ™‚ç³»åˆ—é•·ã¨åˆæœŸéæ¸¡ã®é™¤å¤– |
| IBPM `-Re` | 100-200 | èˆˆå‘³æ·±ã„æµã‚Œæ§‹é€ ï¼ˆã‚«ãƒ«ãƒãƒ³æ¸¦åˆ—ï¼‰ |
| Coarsen factor | 4 | 256Ã—256 â†’ 64Ã—64 (Kolmogorov ã¨åŒã˜) |
| Window size | 64 | SDAã®æ¨™æº–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º |
| Batch size | 16-32 | ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¿œã˜ã¦èª¿æ•´ |
| Learning rate | 1e-4 | å®‰å®šã—ãŸå­¦ç¿’ã®ãŸã‚ |
| Epochs | 2048 | ååˆ†ãªåæŸæ™‚é–“ |
| Dtype | float32 | å­¦ç¿’åŠ¹ç‡ã¨ãƒ¡ãƒ¢ãƒªã®ãƒãƒ©ãƒ³ã‚¹ |
| HDF5 compression | gzip level 4 | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå‰Šæ¸› |

### æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] IBPMã§è¤‡æ•°å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆæœ€ä½3ã¤ä»¥ä¸Šæ¨å¥¨ï¼‰
- [ ] å„å®Ÿé¨“ã§200ã‚¹ãƒ†ãƒƒãƒ—ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
- [ ] å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§HDF5å½¢å¼ã«å¤‰æ›å®Œäº†
- [ ] ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ãŒ`(n_samples, 64, 2, 64, 64)`ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] æ­£è¦åŒ–ã‚’é©ç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- [ ] SDAå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ`utils.py`, `train.py`ï¼‰ã‚’ä½œæˆ
- [ ] å­¦ç¿’ã‚’é–‹å§‹ã—ã€lossæ›²ç·šã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- [ ] ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ãŒç‰©ç†çš„ã«å¦¥å½“ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã•ã‚‰ãªã‚‹æ”¹å–„

1. **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ**: è¤‡æ•°ã®ãƒ¬ã‚¤ãƒãƒ«ã‚ºæ•°ã€å¹¾ä½•å½¢çŠ¶ã§IBPMå®Ÿé¨“
2. **æ­£è¦åŒ–ã®æœ€é©åŒ–**: å„ç‰©ç†é‡ã«å¿œã˜ãŸæ­£è¦åŒ–æ‰‹æ³•
3. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: learning rate, batch sizeç­‰
4. **é•·æ™‚é–“äºˆæ¸¬**: ã‚ˆã‚Šé•·ã„windowã‚µã‚¤ã‚ºã§ã®å­¦ç¿’
5. **é«˜è§£åƒåº¦åŒ–**: 128Ã—128ã‚„256Ã—256ã§ã®å­¦ç¿’

ã“ã‚Œã§ã€IBPMã§ç”Ÿæˆã—ãŸæµä½“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’SDAã§å­¦ç¿’ã—ã€æ–°ã—ã„æµã‚Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼
